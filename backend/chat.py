import os
import re
from fastapi import APIRouter, HTTPException, Form, Request
import sqlite3
from db import DB_NAME
from openai import OpenAI
from audio import generate_audio
from fastapi.staticfiles import StaticFiles

chat_router = APIRouter()
client = OpenAI(
    api_key=""
)

# ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯ÙˆØ§Ø±
story_turns = {}

def get_story_length_for_grade(grade_level: str):
    if grade_level == 'KG':
        return "Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ø­ÙˆØ§Ù„ÙŠ 40 Ø¥Ù„Ù‰ 60 ÙƒÙ„Ù…Ø©)"
    elif grade_level in ['G1', 'G2']:
        return "Ù‚ØµÙŠØ±Ø© (Ø­ÙˆØ§Ù„ÙŠ 80 Ø¥Ù„Ù‰ 100 ÙƒÙ„Ù…Ø©)"
    else:
        return "Ù…ØªÙˆØ³Ø·Ø© (Ø­ÙˆØ§Ù„ÙŠ 120 ÙƒÙ„Ù…Ø©)"

# Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ§Ù‚ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† ÙˆØ³Ø· Ù…Ø³Ø§ÙØ§Øª
def extract_story_and_mode(full_response: str):
    # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ§Ù‚ ÙÙŠ Ø£ÙŠ Ù…ÙƒØ§Ù† ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ù†Øµ
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„ØªØ§Ù‚Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
    modes = ["TILTZ", "TILTY", "SHAKE", "FINISH"]
    found_mode = "TILTZ" # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ§Ù‚ Ù„Ù„ÙŠÙ…ÙŠÙ†/Ø§Ù„ÙŠØ³Ø§Ø±
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
    clean_response = full_response.strip()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± ØªØ§Ù‚ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ
    matches = re.findall(r"\[(TILTZ|TILTY|SHAKE|FINISH)\]", clean_response.upper())
    
    if matches:
        found_mode = matches[-1] # Ù†Ø£Ø®Ø° Ø¢Ø®Ø± ØªØ§Ù‚ ÙˆØ¬Ø¯Ù†Ø§Ù‡
        # Ù†Ø­Ø°Ù Ø§Ù„ØªØ§Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù‚ØµØ© ÙÙ‚Ø·
        story_part = re.sub(r"\[(TILTZ|TILTY|SHAKE|FINISH)\]", "", clean_response).strip()
        return story_part, found_mode
    
    return clean_response, found_mode

def get_max_turns(age: int):
    if age <= 5: return 3
    elif age <= 8: return 5
    return 7

# Ø¯Ø§Ù„Ø© Ù„ØªØ±Ø¬Ù…Ø© Ø±Ø¯ Ø§Ù„Ù…ÙƒØ¹Ø¨ Ø¥Ù„Ù‰ Ø¬Ù…Ù„Ø© Ø¹Ø±Ø¨ÙŠØ© ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ø±Ø§ÙˆÙŠ
def translate_answer_to_context(answer: str):
    answer = answer.upper().strip()
    if "LEFT" in answer:
        return "Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ø¥Ù…Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ¹Ø¨ Ù„Ù„ÙŠØ³Ø§Ø± (Ø§Ø®ØªØ§Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£ÙŠØ³Ø±)."
    elif "RIGHT" in answer:
        return "Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ø¥Ù…Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ¹Ø¨ Ù„Ù„ÙŠÙ…ÙŠÙ† (Ø§Ø®ØªØ§Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£ÙŠÙ…Ù†)."
    elif "FRONT" in answer:
        return "Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ø¥Ù…Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ¹Ø¨ Ù„Ù„Ø£Ù…Ø§Ù…."
    elif "BACK" in answer:
        return "Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ø¥Ù…Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ¹Ø¨ Ù„Ù„Ø®Ù„Ù."
    elif "SHAKE" in answer:
        return "Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ù‡Ø² Ø§Ù„Ù…ÙƒØ¹Ø¨ Ø¨Ù‚ÙˆØ©."
    else:
        return f"Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø±: {answer}"

@chat_router.post("/start/")
def start_story(
    request: Request,
    userID: int = Form(...),
    childID: int = Form(...),
    genre: str = Form(...),
    description: str = Form(...)
):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute("SELECT name, age, gender, grade FROM children WHERE childID=? AND userID=?", (childID, userID))
    row = c.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Child not found")
    
    name, age, gender, grade = row
    story_length_prompt = get_story_length_for_grade(grade)
    child_info = f"Ø§Ù„Ø·ÙÙ„ Ø§Ø³Ù…Ù‡ {name}ØŒ Ø¹Ù…Ø±Ù‡ {age}ØŒ Ø¬Ù†Ø³Ù‡ {gender}ØŒ ÙˆÙ…Ø³ØªÙˆØ§Ù‡ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ {grade}."
    prefs = f"Ù†ÙˆØ¹ Ø§Ù„Ù‚ØµØ©: {genre}Ø› ÙˆØµÙ Ø¥Ø¶Ø§ÙÙŠ: {description}."
    
    system_prompt = (
        "Ø£Ù†Øª 'ÙƒÙŠÙˆØ¨ÙŠ'ØŒ Ø±Ø§ÙˆÙŠ Ù‚ØµØµ ØªÙØ§Ø¹Ù„ÙŠØ© Ø°ÙƒÙŠ Ù„Ù„Ø£Ø·ÙØ§Ù„. ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ÙˆØ§Ù„Ù…Ù…ØªØ¹Ø©."
        f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·ÙÙ„: {child_info} {prefs}"
    )
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„ØªØ§Ù‚
    user_task_prompt = (
        f"Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù‚ØµØ© Ø¨Ù…Ù‚Ø¯Ù…Ø© Ù…Ø´ÙˆÙ‚Ø©. Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {story_length_prompt}.\n"
        "Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©: ÙŠØ¬Ø¨ Ø£Ù† ØªÙ†Ù‡ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø¨Ø³Ø¤Ø§Ù„ ÙŠØ·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø·ÙÙ„ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø­Ø±ÙƒØ© Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.\n"
        "Ø§Ø®ØªØ± Ù†ÙˆØ¹Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¶Ù Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù†Øµ ØªÙ…Ø§Ù…Ø§Ù‹:\n\n"
        "1. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ø®ØªÙŠØ§Ø± Ø§ØªØ¬Ø§Ù‡ (ÙŠÙ…ÙŠÙ† Ø£Ùˆ ÙŠØ³Ø§Ø±): Ø§ÙƒØªØ¨ Ø§Ù„Ù‚ØµØ© Ø«Ù… [TILTZ]\n"
        "2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ø®ØªÙŠØ§Ø± (Ø£Ù…Ø§Ù… Ø£Ùˆ Ø®Ù„Ù): Ø§ÙƒØªØ¨ Ø§Ù„Ù‚ØµØ© Ø«Ù… [TILTY]\n"
        "3. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØªØ·Ù„Ø¨ Ø­Ø±ÙƒØ© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø£Ùˆ Ù…Ø´ÙˆÙ‚Ø© (Ù…Ø«Ù„: Ù‡Ø² Ø§Ù„Ø´Ø¬Ø±Ø©ØŒ Ø§Ø±ÙƒØ¶): Ø§ÙƒØªØ¨ Ø§Ù„Ù‚ØµØ© Ø«Ù… [SHAKE]\n\n"
        "Ù…Ø«Ø§Ù„: '...Ù‡Ù„ ÙŠØ°Ù‡Ø¨ Ù„Ù„ÙŠÙ…ÙŠÙ† Ù†Ø­Ùˆ Ø§Ù„ØºØ§Ø¨Ø© Ø£Ù… Ù„Ù„ÙŠØ³Ø§Ø± Ù†Ø­Ùˆ Ø§Ù„Ù†Ù‡Ø±ØŸ' [TILTZ]"
    )

    print("ğŸ”„ [OpenAI] Start Story...")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_task_prompt}
        ]
    )
    
    full_response_text = response.choices[0].message.content
    first_part, question_mode = extract_story_and_mode(full_response_text)

    c.execute("""
        INSERT INTO stories (userID, genre, preferences, prompt, generated_story, audio_path)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (userID, genre, description, user_task_prompt, first_part, None))
    conn.commit()
    story_id = c.lastrowid
    conn.close()

    story_turns[story_id] = {"turns": 1, "max_turns": get_max_turns(age)}
    
    print(f"ğŸ§ [Audio] Generating part 1...")
    audio_path = generate_audio(first_part, userID, story_id, turn=1)
    base_url = str(request.base_url).rstrip("/")
    audio_url = f"{base_url}/audio_files/{userID}/{story_id}/{os.path.basename(audio_path)}"

    return {
        "storyID": story_id, 
        "childID": childID, 
        "text": first_part, 
        "audio_url": audio_url,
        "story_end": False,
        "required_move": question_mode
    }

@chat_router.post("/continue/")
def continue_story(
    request: Request,
    storyID: int = Form(...),
    userID: int = Form(...),
    childID: int = Form(...),
    answer: str = Form(...)
):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    
    c.execute("SELECT generated_story FROM stories WHERE storyID=? AND userID=?", (storyID, userID))
    row = c.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Story not found")
    old_story = row[0]

    c.execute("SELECT name, age, gender, grade FROM children WHERE childID=? AND userID=?", (childID, userID))
    child_row = c.fetchone()
    if not child_row:
        conn.close()
        raise HTTPException(status_code=404, detail="Child not found")
        
    name, age, gender, grade = child_row
    story_length_prompt = get_story_length_for_grade(grade)

    if storyID not in story_turns:
        story_turns[storyID] = {"turns": 1, "max_turns": get_max_turns(age)}
    turns_info = story_turns[storyID]
    turns_info["turns"] += 1
    turns, max_turns = turns_info["turns"], turns_info["max_turns"]

    # ØªØ±Ø¬Ù…Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø·ÙÙ„ Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    child_action_desc = translate_answer_to_context(answer)

    base_system_prompt = (
        "Ø£Ù†Øª 'ÙƒÙŠÙˆØ¨ÙŠ'ØŒ Ø±Ø§ÙˆÙŠ Ù‚ØµØµ ØªÙØ§Ø¹Ù„ÙŠØ© Ù„Ù„Ø£Ø·ÙØ§Ù„."
        f"Ø§Ù„Ø·ÙÙ„: {name}, {age} Ø³Ù†ÙˆØ§Øª."
    )
    
    # ØªØ²ÙˆÙŠØ¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„: Ø§Ù„Ù‚ØµØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© + Ù…Ø§Ø°Ø§ ÙØ¹Ù„ Ø§Ù„Ø·ÙÙ„ Ø¨Ø§Ù„Ø¶Ø¨Ø·
    message_history = [
        {"role": "system", "content": base_system_prompt},
        {"role": "assistant", "content": old_story}, # Ø§Ù„Ù‚ØµØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        {"role": "user", "content": f"Ø­Ø¯Ø« Ø§Ù„Ø¢Ù†: {child_action_desc}"} # Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    ]

    if turns >= max_turns:
        instruction = (
            f"Ø§ÙƒØªØ¨ Ø®Ø§ØªÙ…Ø© Ù„Ù„Ù‚ØµØ© ({story_length_prompt}) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø·ÙÙ„ Ø§Ù„Ø£Ø®ÙŠØ±.\n"
            "Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø³Ø¹ÙŠØ¯Ø© ÙˆÙ…Ù†Ø§Ø³Ø¨Ø©.\n"
            "ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„Ù†Øµ Ø¨Ù€ [FINISH] ÙÙ‚Ø·."
        )
        finished = True
    else:
        instruction = (
            f"Ø§ÙƒÙ…Ù„ Ø§Ù„Ù‚ØµØ© Ø¨Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯ ({story_length_prompt}) ÙŠØªØ±ØªØ¨ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø·ÙÙ„.\n"
            "Ø«Ù… Ø§Ù†Ù‡Ù Ø§Ù„ÙÙ‚Ø±Ø© Ø¨Ø³Ø¤Ø§Ù„ ØªÙØ§Ø¹Ù„ÙŠ Ø¬Ø¯ÙŠØ¯.\n"
            "Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:\n"
            "- Ù„Ø³Ø¤Ø§Ù„ ÙŠÙ…ÙŠÙ†/ÙŠØ³Ø§Ø±: Ø§Ù†Ù‡Ù Ø§Ù„Ù†Øµ Ø¨Ù€ [TILTZ]\n"
            "- Ù„Ø³Ø¤Ø§Ù„ Ø£Ù…Ø§Ù…/Ø®Ù„Ù: Ø§Ù†Ù‡Ù Ø§Ù„Ù†Øµ Ø¨Ù€ [TILTY]\n"
            "- Ù„Ø³Ø¤Ø§Ù„ Ù‡Ø²/Ø­Ø±ÙƒØ©: Ø§Ù†Ù‡Ù Ø§Ù„Ù†Øµ Ø¨Ù€ [SHAKE]\n"
            "Ø§Ù„ØªØ²Ù… Ø¨ÙˆØ¶Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ø°ÙŠ ÙŠØ·Ø§Ø¨Ù‚ Ø³Ø¤Ø§Ù„Ùƒ."
        )
        finished = False
        
    message_history.append({"role": "system", "content": instruction})

    print(f"ğŸ”„ [OpenAI] Continue Turn {turns}...")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=message_history
    )
    
    full_response_text = response.choices[0].message.content
    new_part, question_mode = extract_story_and_mode(full_response_text)
    
    if finished:
        question_mode = "FINISH"

    updated_story = old_story + "\n\n" + new_part
    c.execute("UPDATE stories SET generated_story=? WHERE storyID=?", (updated_story, storyID))
    conn.commit()
    conn.close()

    print(f"ğŸ§ [Audio] Generating Turn {turns}...")
    audio_path = generate_audio(new_part, userID, storyID, turn=turns)
    base_url = str(request.base_url).rstrip("/")
    audio_url = f"{base_url}/audio_files/{userID}/{storyID}/{os.path.basename(audio_path)}"

    return {
        "storyID": storyID, 
        "childID": childID, 
        "text": new_part,
        "audio_url": audio_url,
        "story_end": finished,
        "required_move": question_mode
    }
